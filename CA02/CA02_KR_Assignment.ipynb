{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCZYXwtCsL_y"
      },
      "source": [
        "CA02: This is a eMail Spam Classifers that uses Naive Bayes supervised machine learning algorithm. \n",
        "\n",
        "In this assignment you will ...\n",
        "1. Complete the code such a way that it works correctly with this given parts of the program.\n",
        "2. Explain as clearly as possible what each part of the code is doing. Use \"Markdown\" texts and code commenting to explain the code\n",
        "\n",
        "IMPORTANT NOTE:\n",
        "\n",
        "The path of your data folders 'train-mails' and 'test-mails' must be './train-mails' and './test-mails'. This means you must have your .ipynb file and these folders in the SAME FOLDER in your laptop or Google Drive. The reason for doing this is, this way the peer reviewes and I would be able to run your code from our computers using this exact same relative path, irrespective of our folder hierarchy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "id": "4p_DvtT7sOIr",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "#Import all of the necessary packages in order to run the model\n",
        "import os\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "id": "jjKF0nIMwz8_",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "#This is creating a function that will first create a dictionary and then go through and split\n",
        "#all of the words and characters, find the ones necessary of removal, and then find the 3000 most common ones\n",
        "def make_Dictionary(root_dir):\n",
        "  all_words = []\n",
        "  emails = [os.path.join(root_dir,f) for f in os.listdir(root_dir)]\n",
        "  for mail in emails:\n",
        "    with open(mail) as m:\n",
        "      for line in m:\n",
        "        words = line.split()\n",
        "        all_words += words #for loop that goes through and uses a space to split all characters and words and append to dictionary\n",
        "  dictionary = Counter(all_words)  \n",
        "  list_to_remove = list(dictionary) #turns the dictionary to a list\n",
        "\n",
        "  for item in list_to_remove:\n",
        "    if item.isalpha() == False:\n",
        "      del dictionary[item] #removes any nonalpha charcaters from the dictionary\n",
        "    elif len(item) == 1:\n",
        "      del dictionary[item] #removes any words that are only a single letter\n",
        "  dictionary = dictionary.most_common(3000) #finds the 3000 most common words in the dictionary\n",
        "  return dictionary            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "id": "dmVW5xNlyOFc",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "#This defines a function that populates a feature matrix of 3000 columns that goes through each email and populates\n",
        "#the value, then it looks at the name of each email to decide if its spam based on the name\n",
        "\n",
        "def extract_features(mail_dir):\n",
        "  files = [os.path.join(mail_dir,fi) for fi in os.listdir(mail_dir)]\n",
        "  features_matrix = np.zeros((len(files),3000)) #matrix based on the 3000 most common words\n",
        "  train_labels = np.zeros(len(files))\n",
        "  count = 1;\n",
        "  docID = 0;\n",
        "  for fil in files:\n",
        "    with open(fil) as fi:\n",
        "      for i, line in enumerate(fi):\n",
        "        if i ==2:\n",
        "          words = line.split() #for loop to enumerate each of the items in the dictionary\n",
        "          for word in words:\n",
        "            wordID = 0\n",
        "            for i, d in enumerate(dictionary):\n",
        "              if d[0] == word:\n",
        "                wordID = i\n",
        "                features_matrix[docID,wordID] = words.count(word) #creates a matrix with the word frequency\n",
        "      train_labels[docID] = 0;\n",
        "      filepathTokens = fil.split('/')\n",
        "      lastToken = filepathTokens[len(filepathTokens)-1]\n",
        "      if lastToken.startswith(\"spmsg\"):\n",
        "        train_labels[docID] = 1;\n",
        "        count = count + 1\n",
        "      docID = docID + 1 #uses the file name to determine if it has spam\n",
        "  return features_matrix, train_labels                "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "id": "zoq-rE7Mx0pp",
        "jupyter": {
          "outputs_hidden": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2246738b-efbb-4b7f-a3c2-e508c38aa5b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# this mounts the drive and recalls the files of our two train and test datasets\n",
        "drive.mount('/content/drive')\n",
        "TRAIN_DIR = '/content/drive/My Drive/CA02/train-mails'\n",
        "TEST_DIR = '/content/drive/My Drive/CA02/test-mails'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "134lmhauyQxE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4201e710-681d-4e17-e048-b033a4878232"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading and processing emails from TRAIN and TEST folders\n",
            "Training Model using Gaussian Naibe Bayes algorithm .....\n",
            "Training completed\n",
            "testing trained model to predict Test Data labels\n",
            "Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\n",
            "0.9655172413793104\n"
          ]
        }
      ],
      "source": [
        "#Trains our model using Naive Bayes algorithm, to then predict, and evaluate our preformance\n",
        "dictionary = make_Dictionary(TRAIN_DIR) #recalls the function above and uses it on out train dataset\n",
        "\n",
        "print (\"reading and processing emails from TRAIN and TEST folders\")\n",
        "features_matrix, labels = extract_features(TRAIN_DIR) #populate the model\n",
        "test_features_matrix, test_labels = extract_features(TEST_DIR)\n",
        "\n",
        "model = GaussianNB() #use Gaussian Naive Bayes model\n",
        "\n",
        "print (\"Training Model using Gaussian Naibe Bayes algorithm .....\")\n",
        "model.fit(features_matrix, labels) #train the model using Gaussian\n",
        "print (\"Training completed\")\n",
        "print (\"testing trained model to predict Test Data labels\")\n",
        "predicted_labels = model.predict(test_features_matrix) #predicts based on the model completed above\n",
        "print (\"Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\")\n",
        "print (accuracy_score(test_labels, predicted_labels)) #print the accuracy of the model to evaluate its preformance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5_mPrvN586A"
      },
      "source": [
        "======================= END OF PROGRAM ========================="
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}